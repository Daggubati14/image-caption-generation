{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image dataset'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91868\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "## Loading the pre-defined VGG model to extract feature and removing last layer\n",
    "\n",
    "model = VGG16()\n",
    "model.layers.pop()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading all 8K images (it icnludes 6K training & 1K validation & 1K testing images)\n",
    "## Extracting all features from images and storing into a dictonary as { dict[image_name] = features }\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "features=dict()\n",
    "for name in listdir('C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image dataset\\\\Flicker8k_Dataset'):\n",
    "        filename = 'C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image dataset\\\\Flicker8k_Dataset' + '//' + name\n",
    "        image = load_img(filename, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        image = preprocess_input(image)\n",
    "        feature = model.predict(image, verbose=0)\n",
    "        image_id = name.split('.')[0]\n",
    "        features[image_id] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5076475, 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is the function to devide all ( Train & Validation & Test features)\n",
    "\n",
    "def features_devide(path):\n",
    "    imgs = open(path,'r')\n",
    "    images = imgs.read()\n",
    "    imgs.close()\n",
    "    \n",
    "    images = images.split('\\n')\n",
    "    images1 = []\n",
    "    for i in images:\n",
    "        images1.append(i.split('.')[0])\n",
    "    \n",
    "    features1 = dict()\n",
    "    for i in images1:\n",
    "        if(i in features.keys()):\n",
    "            features1[i] = features[i]\n",
    "    return features1\n",
    "\n",
    "Dev_features = features_devide('C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image captions\\\\Flickr_8k.devImages.txt')\n",
    "test_features = features_devide('C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image captions\\\\Flickr_8k.testImages.txt')\n",
    "Train_features = features_devide('C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image captions\\\\Flickr_8k.trainImages.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "5999\n"
     ]
    }
   ],
   "source": [
    "print(len(Dev_features))\n",
    "print(len(test_features))\n",
    "print(len(Train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading all descriptions file and storing into an object\n",
    "\n",
    "txt_file = open('C:\\\\Users\\\\91868\\\\Desktop\\\\Hari Data science\\\\Image captions\\\\Flickr8k.lemma.token.txt', 'r')\n",
    "text = txt_file.read()\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## storing all descriptions into a dictonary. single image have multiple descriptions those are taken from different sources\n",
    "\n",
    "descriptions = dict()\n",
    "for line in text.split('\\n'):\n",
    "    tokens = line.split('\\t')\n",
    "    image_id, image_desc = tokens[0], tokens[1:]\n",
    "    image_id = image_id.split('.')[0]\n",
    "    if image_id not in descriptions:\n",
    "        descriptions[image_id] = image_desc\n",
    "    else:\n",
    "        descriptions[image_id].append(str(image_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['man in street racer armor be examine the tire of another racer motorbike',\n",
       " 'two racer drive white bike down road',\n",
       " 'two motorist be ride along on their vehicle that be oddly design and color',\n",
       " 'two person be in small race car drive by green hill',\n",
       " 'two person in race uniform in street car']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions['1305564994_00513f9a5b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Cleansing activity on all descriptions like ( converting all into lower, removing 1 length words etc )\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for key, desc_list in descriptions.items():\n",
    "    for i in range(len(desc_list)):\n",
    "        desc = desc_list[i]\n",
    "        desc = desc.split()\n",
    "        desc = [word.lower() for word in desc]\n",
    "        desc = [w.translate(table) for w in desc]\n",
    "        desc = [word for word in desc if len(word)>1]\n",
    "        desc = [word for word in desc if word.isalpha()]\n",
    "        desc_list[i] =  ' '.join(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is the function to devide all descriptions based on image_id\n",
    "\n",
    "def descriptions_devide(features):\n",
    "    descs = dict()\n",
    "    for key,desc in descriptions.items():\n",
    "        if key in features.keys():\n",
    "            if(key in descs):\n",
    "                descs[key].append(str(desc))\n",
    "            else:\n",
    "                descs[key] = desc\n",
    "    return descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "Train_descriptions = descriptions_devide(Train_features)\n",
    "Dev_descriptions = descriptions_devide(Dev_features)\n",
    "test_descriptions = descriptions_devide(test_features)\n",
    "\n",
    "print(len(Train_descriptions))\n",
    "print(len(Dev_descriptions))\n",
    "print(len(test_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6687\n"
     ]
    }
   ],
   "source": [
    "## Here we are reading all descriptions into one list to understand total no.of words \n",
    "## tokenizer.fit_on_texts - will help us to provide indexing for all words ( it will be helpful in language generaion) \n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "all_desc = list()\n",
    "for key in descriptions.keys():\n",
    "    for d in descriptions[key]:\n",
    "        all_desc.append(d)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_desc)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 1,\n",
       " 'be': 2,\n",
       " 'on': 3,\n",
       " 'the': 4,\n",
       " 'dog': 5,\n",
       " 'and': 6,\n",
       " 'man': 7,\n",
       " 'with': 8,\n",
       " 'of': 9,\n",
       " 'two': 10,\n",
       " 'boy': 11,\n",
       " 'girl': 12,\n",
       " 'woman': 13,\n",
       " 'person': 14,\n",
       " 'white': 15,\n",
       " 'black': 16,\n",
       " 'run': 17,\n",
       " 'play': 18,\n",
       " 'wear': 19,\n",
       " 'stand': 20,\n",
       " 'to': 21,\n",
       " 'at': 22,\n",
       " 'jump': 23,\n",
       " 'water': 24,\n",
       " 'child': 25,\n",
       " 'young': 26,\n",
       " 'red': 27,\n",
       " 'an': 28,\n",
       " 'brown': 29,\n",
       " 'his': 30,\n",
       " 'sit': 31,\n",
       " 'blue': 32,\n",
       " 'through': 33,\n",
       " 'walk': 34,\n",
       " 'while': 35,\n",
       " 'hold': 36,\n",
       " 'shirt': 37,\n",
       " 'ball': 38,\n",
       " 'down': 39,\n",
       " 'little': 40,\n",
       " 'ride': 41,\n",
       " 'grass': 42,\n",
       " 'look': 43,\n",
       " 'snow': 44,\n",
       " 'over': 45,\n",
       " 'front': 46,\n",
       " 'three': 47,\n",
       " 'small': 48,\n",
       " 'field': 49,\n",
       " 'large': 50,\n",
       " 'up': 51,\n",
       " 'by': 52,\n",
       " 'green': 53,\n",
       " 'group': 54,\n",
       " 'one': 55,\n",
       " 'yellow': 56,\n",
       " 'her': 57,\n",
       " 'into': 58,\n",
       " 'air': 59,\n",
       " 'beach': 60,\n",
       " 'mouth': 61,\n",
       " 'near': 62,\n",
       " 'player': 63,\n",
       " 'rock': 64,\n",
       " 'dress': 65,\n",
       " 'bike': 66,\n",
       " 'street': 67,\n",
       " 'another': 68,\n",
       " 'for': 69,\n",
       " 'its': 70,\n",
       " 'from': 71,\n",
       " 'as': 72,\n",
       " 'climb': 73,\n",
       " 'watch': 74,\n",
       " 'outside': 75,\n",
       " 'other': 76,\n",
       " 'hat': 77,\n",
       " 'smile': 78,\n",
       " 'out': 79,\n",
       " 'mountain': 80,\n",
       " 'next': 81,\n",
       " 'jacket': 82,\n",
       " 'off': 83,\n",
       " 'orange': 84,\n",
       " 'pink': 85,\n",
       " 'do': 86,\n",
       " 'camera': 87,\n",
       " 'their': 88,\n",
       " 'pool': 89,\n",
       " 'have': 90,\n",
       " 'tree': 91,\n",
       " 'race': 92,\n",
       " 'pose': 93,\n",
       " 'around': 94,\n",
       " 'swim': 95,\n",
       " 'swing': 96,\n",
       " 'behind': 97,\n",
       " 'toy': 98,\n",
       " 'catch': 99,\n",
       " 'some': 100,\n",
       " 'park': 101,\n",
       " 'face': 102,\n",
       " 'skateboard': 103,\n",
       " 'stick': 104,\n",
       " 'hand': 105,\n",
       " 'background': 106,\n",
       " 'carry': 107,\n",
       " 'dirt': 108,\n",
       " 'building': 109,\n",
       " 'soccer': 110,\n",
       " 'wall': 111,\n",
       " 'crowd': 112,\n",
       " 'along': 113,\n",
       " 'kid': 114,\n",
       " 'slide': 115,\n",
       " 'wave': 116,\n",
       " 'top': 117,\n",
       " 'car': 118,\n",
       " 'four': 119,\n",
       " 'take': 120,\n",
       " 'trick': 121,\n",
       " 'football': 122,\n",
       " 'picture': 123,\n",
       " 'hill': 124,\n",
       " 'across': 125,\n",
       " 'bicycle': 126,\n",
       " 'grassy': 127,\n",
       " 'sand': 128,\n",
       " 'ocean': 129,\n",
       " 'people': 130,\n",
       " 'short': 131,\n",
       " 'head': 132,\n",
       " 'each': 133,\n",
       " 'baby': 134,\n",
       " 'tennis': 135,\n",
       " 'snowy': 136,\n",
       " 'back': 137,\n",
       " 'together': 138,\n",
       " 'hair': 139,\n",
       " 'him': 140,\n",
       " 'it': 141,\n",
       " 'gray': 142,\n",
       " 'area': 143,\n",
       " 'basketball': 144,\n",
       " 'old': 145,\n",
       " 'that': 146,\n",
       " 'helmet': 147,\n",
       " 'arm': 148,\n",
       " 'bench': 149,\n",
       " 'tan': 150,\n",
       " 'road': 151,\n",
       " 'blond': 152,\n",
       " 'uniform': 153,\n",
       " 'leap': 154,\n",
       " 'sidewalk': 155,\n",
       " 'game': 156,\n",
       " 'ground': 157,\n",
       " 'cover': 158,\n",
       " 'fence': 159,\n",
       " 'something': 160,\n",
       " 'make': 161,\n",
       " 'get': 162,\n",
       " 'chase': 163,\n",
       " 'frisbee': 164,\n",
       " 'lake': 165,\n",
       " 'ramp': 166,\n",
       " 'side': 167,\n",
       " 'skateboarder': 168,\n",
       " 'path': 169,\n",
       " 'horse': 170,\n",
       " 'perform': 171,\n",
       " 'track': 172,\n",
       " 'boat': 173,\n",
       " 'city': 174,\n",
       " 'fly': 175,\n",
       " 'several': 176,\n",
       " 'purple': 177,\n",
       " 'try': 178,\n",
       " 'suit': 179,\n",
       " 'there': 180,\n",
       " 'sign': 181,\n",
       " 'baseball': 182,\n",
       " 'coat': 183,\n",
       " 'ski': 184,\n",
       " 'big': 185,\n",
       " 'rope': 186,\n",
       " 'guy': 187,\n",
       " 'high': 188,\n",
       " 'throw': 189,\n",
       " 'long': 190,\n",
       " 'wooden': 191,\n",
       " 'wood': 192,\n",
       " 'motorcycle': 193,\n",
       " 'table': 194,\n",
       " 'sunglasses': 195,\n",
       " 'go': 196,\n",
       " 'splash': 197,\n",
       " 'lay': 198,\n",
       " 'lady': 199,\n",
       " 'drink': 200,\n",
       " 'dance': 201,\n",
       " 'them': 202,\n",
       " 'hang': 203,\n",
       " 'pants': 204,\n",
       " 'couple': 205,\n",
       " 'jean': 206,\n",
       " 'snowboarder': 207,\n",
       " 'dark': 208,\n",
       " 'towards': 209,\n",
       " 'beside': 210,\n",
       " 'talk': 211,\n",
       " 'under': 212,\n",
       " 'rocky': 213,\n",
       " 'team': 214,\n",
       " 'bird': 215,\n",
       " 'colorful': 216,\n",
       " 'river': 217,\n",
       " 'adult': 218,\n",
       " 'above': 219,\n",
       " 'eat': 220,\n",
       " 'kick': 221,\n",
       " 'outfit': 222,\n",
       " 'ice': 223,\n",
       " 'open': 224,\n",
       " 'fall': 225,\n",
       " 'rider': 226,\n",
       " 'pull': 227,\n",
       " 'who': 228,\n",
       " 'flower': 229,\n",
       " 'light': 230,\n",
       " 'skier': 231,\n",
       " 'bag': 232,\n",
       " 'fight': 233,\n",
       " 'striped': 234,\n",
       " 'cap': 235,\n",
       " 'costume': 236,\n",
       " 'pole': 237,\n",
       " 'onto': 238,\n",
       " 'midair': 239,\n",
       " 'collar': 240,\n",
       " 'he': 241,\n",
       " 'surfer': 242,\n",
       " 'surround': 243,\n",
       " 'surf': 244,\n",
       " 'glasses': 245,\n",
       " 'wait': 246,\n",
       " 'set': 247,\n",
       " 'cliff': 248,\n",
       " 'biker': 249,\n",
       " 'asian': 250,\n",
       " 'playground': 251,\n",
       " 'against': 252,\n",
       " 'yard': 253,\n",
       " 'chair': 254,\n",
       " 'backpack': 255,\n",
       " 'skate': 256,\n",
       " 'line': 257,\n",
       " 'step': 258,\n",
       " 'fountain': 259,\n",
       " 'hockey': 260,\n",
       " 'body': 261,\n",
       " 'leg': 262,\n",
       " 'many': 263,\n",
       " 'after': 264,\n",
       " 'lean': 265,\n",
       " 'toddler': 266,\n",
       " 'wet': 267,\n",
       " 'flag': 268,\n",
       " 'brick': 269,\n",
       " 'guitar': 270,\n",
       " 'fish': 271,\n",
       " 'outdoors': 272,\n",
       " 'inside': 273,\n",
       " 'during': 274,\n",
       " 'edge': 275,\n",
       " 'others': 276,\n",
       " 'shore': 277,\n",
       " 'away': 278,\n",
       " 'board': 279,\n",
       " 'paint': 280,\n",
       " 'very': 281,\n",
       " 'floor': 282,\n",
       " 'forest': 283,\n",
       " 'tshirt': 284,\n",
       " 'someone': 285,\n",
       " 'object': 286,\n",
       " 'five': 287,\n",
       " 'trail': 288,\n",
       " 'show': 289,\n",
       " 'bed': 290,\n",
       " 'sky': 291,\n",
       " 'middle': 292,\n",
       " 'laugh': 293,\n",
       " 'night': 294,\n",
       " 'hit': 295,\n",
       " 'read': 296,\n",
       " 'bright': 297,\n",
       " 'bite': 298,\n",
       " 'leash': 299,\n",
       " 'snowboard': 300,\n",
       " 'puppy': 301,\n",
       " 'nearby': 302,\n",
       " 'surfboard': 303,\n",
       " 'colored': 304,\n",
       " 'about': 305,\n",
       " 'whilst': 306,\n",
       " 'shop': 307,\n",
       " 'climber': 308,\n",
       " 'house': 309,\n",
       " 'bar': 310,\n",
       " 'tall': 311,\n",
       " 'past': 312,\n",
       " 'window': 313,\n",
       " 'drive': 314,\n",
       " 'toward': 315,\n",
       " 'lie': 316,\n",
       " 'haired': 317,\n",
       " 'point': 318,\n",
       " 'train': 319,\n",
       " 'this': 320,\n",
       " 'bridge': 321,\n",
       " 'jersey': 322,\n",
       " 'animal': 323,\n",
       " 'push': 324,\n",
       " 'leaf': 325,\n",
       " 'sled': 326,\n",
       " 'day': 327,\n",
       " 'outdoor': 328,\n",
       " 'all': 329,\n",
       " 'turn': 330,\n",
       " 'stone': 331,\n",
       " 'course': 332,\n",
       " 'clothes': 333,\n",
       " 'smoke': 334,\n",
       " 'obstacle': 335,\n",
       " 'shallow': 336,\n",
       " 'flip': 337,\n",
       " 'sweater': 338,\n",
       " 'room': 339,\n",
       " 'plastic': 340,\n",
       " 'attempt': 341,\n",
       " 'clothing': 342,\n",
       " 'lot': 343,\n",
       " 'ready': 344,\n",
       " 'male': 345,\n",
       " 'gather': 346,\n",
       " 'kayak': 347,\n",
       " 'bubble': 348,\n",
       " 'blow': 349,\n",
       " 'greyhound': 350,\n",
       " 'between': 351,\n",
       " 'paddle': 352,\n",
       " 'number': 353,\n",
       " 'railing': 354,\n",
       " 'come': 355,\n",
       " 'bathe': 356,\n",
       " 'tire': 357,\n",
       " 'fire': 358,\n",
       " 'wrestle': 359,\n",
       " 'stair': 360,\n",
       " 'eye': 361,\n",
       " 'trunk': 362,\n",
       " 'seat': 363,\n",
       " 'they': 364,\n",
       " 'overlook': 365,\n",
       " 'female': 366,\n",
       " 'concrete': 367,\n",
       " 'store': 368,\n",
       " 'vest': 369,\n",
       " 'tongue': 370,\n",
       " 'trampoline': 371,\n",
       " 'lawn': 372,\n",
       " 'winter': 373,\n",
       " 'gear': 374,\n",
       " 'stream': 375,\n",
       " 'hiker': 376,\n",
       " 'mud': 377,\n",
       " 'hug': 378,\n",
       " 'metal': 379,\n",
       " 'rail': 380,\n",
       " 'shake': 381,\n",
       " 'scarf': 382,\n",
       " 'sandy': 383,\n",
       " 'reach': 384,\n",
       " 'tent': 385,\n",
       " 'dive': 386,\n",
       " 'distance': 387,\n",
       " 'ear': 388,\n",
       " 'golden': 389,\n",
       " 'sun': 390,\n",
       " 'shoe': 391,\n",
       " 'kiss': 392,\n",
       " 'use': 393,\n",
       " 'shirtless': 394,\n",
       " 'couch': 395,\n",
       " 'skirt': 396,\n",
       " 'cellphone': 397,\n",
       " 'photo': 398,\n",
       " 'vehicle': 399,\n",
       " 'sport': 400,\n",
       " 'men': 401,\n",
       " 'wooded': 402,\n",
       " 'busy': 403,\n",
       " 'raft': 404,\n",
       " 'bat': 405,\n",
       " 'nose': 406,\n",
       " 'dock': 407,\n",
       " 'hike': 408,\n",
       " 'cyclist': 409,\n",
       " 'box': 410,\n",
       " 'cart': 411,\n",
       " 'umbrella': 412,\n",
       " 'puddle': 413,\n",
       " 'truck': 414,\n",
       " 'right': 415,\n",
       " 'pond': 416,\n",
       " 'upside': 417,\n",
       " 'roll': 418,\n",
       " 'mask': 419,\n",
       " 'harness': 420,\n",
       " 'put': 421,\n",
       " 'spray': 422,\n",
       " 'huge': 423,\n",
       " 'stunt': 424,\n",
       " 'sunset': 425,\n",
       " 'hurdle': 426,\n",
       " 'she': 427,\n",
       " 'prepare': 428,\n",
       " 'food': 429,\n",
       " 'rest': 430,\n",
       " 'american': 431,\n",
       " 'canoe': 432,\n",
       " 'waterfall': 433,\n",
       " 'follow': 434,\n",
       " 'raise': 435,\n",
       " 'view': 436,\n",
       " 'stare': 437,\n",
       " 'paper': 438,\n",
       " 'row': 439,\n",
       " 'no': 440,\n",
       " 'ring': 441,\n",
       " 'or': 442,\n",
       " 'bicyclist': 443,\n",
       " 'cross': 444,\n",
       " 'feet': 445,\n",
       " 'enjoy': 446,\n",
       " 'hoop': 447,\n",
       " 'family': 448,\n",
       " 'restaurant': 449,\n",
       " 'block': 450,\n",
       " 'slope': 451,\n",
       " 'equipment': 452,\n",
       " 'float': 453,\n",
       " 'life': 454,\n",
       " 'bus': 455,\n",
       " 'book': 456,\n",
       " 'dry': 457,\n",
       " 'wetsuit': 458,\n",
       " 'elderly': 459,\n",
       " 'chew': 460,\n",
       " 'goal': 461,\n",
       " 'pile': 462,\n",
       " 'move': 463,\n",
       " 'deep': 464,\n",
       " 'both': 465,\n",
       " 'bottle': 466,\n",
       " 'like': 467,\n",
       " 'cigarette': 468,\n",
       " 'structure': 469,\n",
       " 'lone': 470,\n",
       " 'tackle': 471,\n",
       " 'sweatshirt': 472,\n",
       " 'pass': 473,\n",
       " 'muddy': 474,\n",
       " 'balance': 475,\n",
       " 'bikini': 476,\n",
       " 'shoulder': 477,\n",
       " 'sleep': 478,\n",
       " 'court': 479,\n",
       " 'give': 480,\n",
       " 'wade': 481,\n",
       " 'wheel': 482,\n",
       " 'bend': 483,\n",
       " 'closeup': 484,\n",
       " 'ledge': 485,\n",
       " 'swimsuit': 486,\n",
       " 'bucket': 487,\n",
       " 'help': 488,\n",
       " 'bmx': 489,\n",
       " 'six': 490,\n",
       " 'tank': 491,\n",
       " 'airborne': 492,\n",
       " 'cement': 493,\n",
       " 'cat': 494,\n",
       " 'german': 495,\n",
       " 'land': 496,\n",
       " 'door': 497,\n",
       " 'photograph': 498,\n",
       " 'subway': 499,\n",
       " 'inflatable': 500,\n",
       " 'sprinkler': 501,\n",
       " 'left': 502,\n",
       " 'teenage': 503,\n",
       " 'close': 504,\n",
       " 'shoot': 505,\n",
       " 'balloon': 506,\n",
       " 'blanket': 507,\n",
       " 'motorcyclist': 508,\n",
       " 'cow': 509,\n",
       " 'goggles': 510,\n",
       " 'piece': 511,\n",
       " 'statue': 512,\n",
       " 'beard': 513,\n",
       " 'parade': 514,\n",
       " 'band': 515,\n",
       " 'microphone': 516,\n",
       " 'muzzle': 517,\n",
       " 'shepherd': 518,\n",
       " 'boot': 519,\n",
       " 'bull': 520,\n",
       " 'log': 521,\n",
       " 'duck': 522,\n",
       " 'full': 523,\n",
       " 'fetch': 524,\n",
       " 'silver': 525,\n",
       " 'see': 526,\n",
       " 'finger': 527,\n",
       " 'backyard': 528,\n",
       " 'tunnel': 529,\n",
       " 'racer': 530,\n",
       " 'sunny': 531,\n",
       " 'low': 532,\n",
       " 'cowboy': 533,\n",
       " 'crowded': 534,\n",
       " 'surface': 535,\n",
       " 'event': 536,\n",
       " 'bald': 537,\n",
       " 'leather': 538,\n",
       " 'wrestler': 539,\n",
       " 'stage': 540,\n",
       " 'tube': 541,\n",
       " 'kneel': 542,\n",
       " 'graffiti': 543,\n",
       " 'scooter': 544,\n",
       " 'spot': 545,\n",
       " 'fluffy': 546,\n",
       " 'art': 547,\n",
       " 'rugby': 548,\n",
       " 'touch': 549,\n",
       " 'sing': 550,\n",
       " 'branch': 551,\n",
       " 'cup': 552,\n",
       " 'corner': 553,\n",
       " 'glove': 554,\n",
       " 'break': 555,\n",
       " 'lead': 556,\n",
       " 'net': 557,\n",
       " 'clear': 558,\n",
       " 'end': 559,\n",
       " 'steep': 560,\n",
       " 'grind': 561,\n",
       " 'teenager': 562,\n",
       " 'tie': 563,\n",
       " 'shot': 564,\n",
       " 'rollerblade': 565,\n",
       " 'glass': 566,\n",
       " 'leave': 567,\n",
       " 'volleyball': 568,\n",
       " 'gold': 569,\n",
       " 'plant': 570,\n",
       " 'furry': 571,\n",
       " 'lift': 572,\n",
       " 'hind': 573,\n",
       " 'same': 574,\n",
       " 'display': 575,\n",
       " 'crossing': 576,\n",
       " 'bowl': 577,\n",
       " 'party': 578,\n",
       " 'attach': 579,\n",
       " 'crouch': 580,\n",
       " 'spectator': 581,\n",
       " 'runner': 582,\n",
       " 'bounce': 583,\n",
       " 'police': 584,\n",
       " 'color': 585,\n",
       " 'few': 586,\n",
       " 'bunch': 587,\n",
       " 'stop': 588,\n",
       " 'say': 589,\n",
       " 'sheep': 590,\n",
       " 'garden': 591,\n",
       " 'onlooker': 592,\n",
       " 'below': 593,\n",
       " 'base': 594,\n",
       " 'instrument': 595,\n",
       " 'beige': 596,\n",
       " 'lick': 597,\n",
       " 'dig': 598,\n",
       " 'desert': 599,\n",
       " 'bottom': 600,\n",
       " 'sniff': 601,\n",
       " 'phone': 602,\n",
       " 'fill': 603,\n",
       " 'rain': 604,\n",
       " 'racket': 605,\n",
       " 'competition': 606,\n",
       " 'friend': 607,\n",
       " 'softball': 608,\n",
       " 'beautiful': 609,\n",
       " 'carpet': 610,\n",
       " 'underwater': 611,\n",
       " 'racetrack': 612,\n",
       " 'fast': 613,\n",
       " 'way': 614,\n",
       " 'headband': 615,\n",
       " 'work': 616,\n",
       " 'bush': 617,\n",
       " 'wide': 618,\n",
       " 'gym': 619,\n",
       " 'bride': 620,\n",
       " 'poodle': 621,\n",
       " 'appear': 622,\n",
       " 'grab': 623,\n",
       " 'spin': 624,\n",
       " 'compete': 625,\n",
       " 'cone': 626,\n",
       " 'which': 627,\n",
       " 'naked': 628,\n",
       " 'gravel': 629,\n",
       " 'motocross': 630,\n",
       " 'empty': 631,\n",
       " 'kite': 632,\n",
       " 'handstand': 633,\n",
       " 'gun': 634,\n",
       " 'wings': 635,\n",
       " 'neck': 636,\n",
       " 'beer': 637,\n",
       " 'speed': 638,\n",
       " 'snowcovered': 639,\n",
       " 'plaid': 640,\n",
       " 'downhill': 641,\n",
       " 'drum': 642,\n",
       " 'platform': 643,\n",
       " 'can': 644,\n",
       " 'stretch': 645,\n",
       " 'pet': 646,\n",
       " 'market': 647,\n",
       " 'mohawk': 648,\n",
       " 'pavement': 649,\n",
       " 'just': 650,\n",
       " 'public': 651,\n",
       " 'african': 652,\n",
       " 'tattoo': 653,\n",
       " 'bear': 654,\n",
       " 'hose': 655,\n",
       " 'rough': 656,\n",
       " 'traffic': 657,\n",
       " 'scene': 658,\n",
       " 'among': 659,\n",
       " 'fenced': 660,\n",
       " 'tug': 661,\n",
       " 'motorbike': 662,\n",
       " 'school': 663,\n",
       " 'parachute': 664,\n",
       " 'cloud': 665,\n",
       " 'oppose': 666,\n",
       " 'happy': 667,\n",
       " 'purse': 668,\n",
       " 'paw': 669,\n",
       " 'cream': 670,\n",
       " 'rural': 671,\n",
       " 'lap': 672,\n",
       " 'bark': 673,\n",
       " 'pack': 674,\n",
       " 'urban': 675,\n",
       " 'different': 676,\n",
       " 'barefoot': 677,\n",
       " 'plate': 678,\n",
       " 'jog': 679,\n",
       " 'landscape': 680,\n",
       " 'kitchen': 681,\n",
       " 'wed': 682,\n",
       " 'teeth': 683,\n",
       " 'goalie': 684,\n",
       " 'practice': 685,\n",
       " 'cricket': 686,\n",
       " 'foot': 687,\n",
       " 'before': 688,\n",
       " 'carnival': 689,\n",
       " 'dirty': 690,\n",
       " 'chain': 691,\n",
       " 'speak': 692,\n",
       " 'mother': 693,\n",
       " 'headphone': 694,\n",
       " 'retrieve': 695,\n",
       " 'newspaper': 696,\n",
       " 'wire': 697,\n",
       " 'match': 698,\n",
       " 'indoor': 699,\n",
       " 'creek': 700,\n",
       " 'stadium': 701,\n",
       " 'crash': 702,\n",
       " 'formation': 703,\n",
       " 'rapid': 704,\n",
       " 'santa': 705,\n",
       " 'pick': 706,\n",
       " 'owner': 707,\n",
       " 'paved': 708,\n",
       " 'round': 709,\n",
       " 'bank': 710,\n",
       " 'onstage': 711,\n",
       " 'third': 712,\n",
       " 'hood': 713,\n",
       " 'shadow': 714,\n",
       " 'deck': 715,\n",
       " 'jeep': 716,\n",
       " 'toss': 717,\n",
       " 'hula': 718,\n",
       " 'foreground': 719,\n",
       " 'cast': 720,\n",
       " 'video': 721,\n",
       " 'bandanna': 722,\n",
       " 'retriever': 723,\n",
       " 'stuff': 724,\n",
       " 'where': 725,\n",
       " 'crawl': 726,\n",
       " 'pipe': 727,\n",
       " 'cut': 728,\n",
       " 'multicolored': 729,\n",
       " 'clown': 730,\n",
       " 'cheerleader': 731,\n",
       " 'atv': 732,\n",
       " 'bearded': 733,\n",
       " 'giant': 734,\n",
       " 'matching': 735,\n",
       " 'playful': 736,\n",
       " 'hole': 737,\n",
       " 'funny': 738,\n",
       " 'staircase': 739,\n",
       " 'skater': 740,\n",
       " 'basket': 741,\n",
       " 'audience': 742,\n",
       " 'place': 743,\n",
       " 'amusement': 744,\n",
       " 'dribble': 745,\n",
       " 'outstretched': 746,\n",
       " 'christmas': 747,\n",
       " 'scale': 748,\n",
       " 'machine': 749,\n",
       " 'fair': 750,\n",
       " 'unicycle': 751,\n",
       " 'stroller': 752,\n",
       " 'officer': 753,\n",
       " 'hay': 754,\n",
       " 'flight': 755,\n",
       " 'wheelie': 756,\n",
       " 'martial': 757,\n",
       " 'begin': 758,\n",
       " 'alongside': 759,\n",
       " 'atop': 760,\n",
       " 'shovel': 761,\n",
       " 'terrier': 762,\n",
       " 'curly': 763,\n",
       " 'gate': 764,\n",
       " 'direction': 765,\n",
       " 'bound': 766,\n",
       " 'computer': 767,\n",
       " 'necklace': 768,\n",
       " 'hoodie': 769,\n",
       " 'handrail': 770,\n",
       " 'silhouette': 771,\n",
       " 'approach': 772,\n",
       " 'travel': 773,\n",
       " 'frame': 774,\n",
       " 'rodeo': 775,\n",
       " 'station': 776,\n",
       " 'swimmer': 777,\n",
       " 'terrain': 778,\n",
       " 'music': 779,\n",
       " 'alone': 780,\n",
       " 'worker': 781,\n",
       " 'denim': 782,\n",
       " 'dune': 783,\n",
       " 'mound': 784,\n",
       " 'fan': 785,\n",
       " 'member': 786,\n",
       " 'ribbon': 787,\n",
       " 'himself': 788,\n",
       " 'start': 789,\n",
       " 'half': 790,\n",
       " 'tricycle': 791,\n",
       " 'squirt': 792,\n",
       " 'backwards': 793,\n",
       " 'string': 794,\n",
       " 'picnic': 795,\n",
       " 'shaggy': 796,\n",
       " 'indoors': 797,\n",
       " 'camel': 798,\n",
       " 'barrier': 799,\n",
       " 'roller': 800,\n",
       " 'pitch': 801,\n",
       " 'guard': 802,\n",
       " 'pigeon': 803,\n",
       " 'cold': 804,\n",
       " 'pier': 805,\n",
       " 'star': 806,\n",
       " 'counter': 807,\n",
       " 'safety': 808,\n",
       " 'cloth': 809,\n",
       " 'referee': 810,\n",
       " 'embrace': 811,\n",
       " 'knee': 812,\n",
       " 'wakeboard': 813,\n",
       " 'writing': 814,\n",
       " 'patch': 815,\n",
       " 'violin': 816,\n",
       " 'construction': 817,\n",
       " 'march': 818,\n",
       " 'size': 819,\n",
       " 'sword': 820,\n",
       " 'ladder': 821,\n",
       " 'policeman': 822,\n",
       " 'item': 823,\n",
       " 'makeup': 824,\n",
       " 'sooner': 825,\n",
       " 'driver': 826,\n",
       " 'sea': 827,\n",
       " 'underneath': 828,\n",
       " 'quick': 829,\n",
       " 'feed': 830,\n",
       " 'participate': 831,\n",
       " 'kayaker': 832,\n",
       " 'waterski': 833,\n",
       " 'seven': 834,\n",
       " 'robe': 835,\n",
       " 'collie': 836,\n",
       " 'peak': 837,\n",
       " 'doorway': 838,\n",
       " 'bare': 839,\n",
       " 'professional': 840,\n",
       " 'sail': 841,\n",
       " 'camouflage': 842,\n",
       " 'cheer': 843,\n",
       " 'rink': 844,\n",
       " 'coach': 845,\n",
       " 'wheelchair': 846,\n",
       " 'these': 847,\n",
       " 'chest': 848,\n",
       " 'stump': 849,\n",
       " 'spread': 850,\n",
       " 'hillside': 851,\n",
       " 'walkway': 852,\n",
       " 'pour': 853,\n",
       " 'screen': 854,\n",
       " 'fur': 855,\n",
       " 'jungle': 856,\n",
       " 'advertise': 857,\n",
       " 'wrap': 858,\n",
       " 'opposite': 859,\n",
       " 'check': 860,\n",
       " 'military': 861,\n",
       " 'lit': 862,\n",
       " 'relax': 863,\n",
       " 'stripe': 864,\n",
       " 'photographer': 865,\n",
       " 'home': 866,\n",
       " 'stuffed': 867,\n",
       " 'tail': 868,\n",
       " 'straw': 869,\n",
       " 'homeless': 870,\n",
       " 'without': 871,\n",
       " 'post': 872,\n",
       " 'karate': 873,\n",
       " 'strip': 874,\n",
       " 'courtyard': 875,\n",
       " 'jockey': 876,\n",
       " 'plain': 877,\n",
       " 'mirror': 878,\n",
       " 'peace': 879,\n",
       " 'headscarf': 880,\n",
       " 'coffee': 881,\n",
       " 'wagon': 882,\n",
       " 'hot': 883,\n",
       " 'wind': 884,\n",
       " 'mat': 885,\n",
       " 'banner': 886,\n",
       " 'blurry': 887,\n",
       " 'emerge': 888,\n",
       " 'monkey': 889,\n",
       " 'knit': 890,\n",
       " 'suspend': 891,\n",
       " 'range': 892,\n",
       " 'candle': 893,\n",
       " 'formal': 894,\n",
       " 'war': 895,\n",
       " 'lab': 896,\n",
       " 'cardboard': 897,\n",
       " 'redheaded': 898,\n",
       " 'listen': 899,\n",
       " 'indian': 900,\n",
       " 'square': 901,\n",
       " 'overall': 902,\n",
       " 'rubber': 903,\n",
       " 'boxer': 904,\n",
       " 'descend': 905,\n",
       " 'miami': 906,\n",
       " 'curve': 907,\n",
       " 'drag': 908,\n",
       " 'medium': 909,\n",
       " 'heavy': 910,\n",
       " 'balcony': 911,\n",
       " 'forward': 912,\n",
       " 'plane': 913,\n",
       " 'musician': 914,\n",
       " 'swan': 915,\n",
       " 'but': 916,\n",
       " 'mountainside': 917,\n",
       " 'tutu': 918,\n",
       " 'father': 919,\n",
       " 'shade': 920,\n",
       " 'thumb': 921,\n",
       " 'dead': 922,\n",
       " 'cheek': 923,\n",
       " 'asleep': 924,\n",
       " 'spiderman': 925,\n",
       " 'barrel': 926,\n",
       " 'mark': 927,\n",
       " 'observe': 928,\n",
       " 'dusk': 929,\n",
       " 'huddle': 930,\n",
       " 'only': 931,\n",
       " 'airplane': 932,\n",
       " 'shoreline': 933,\n",
       " 'puck': 934,\n",
       " 'mountaintop': 935,\n",
       " 'attire': 936,\n",
       " 'coaster': 937,\n",
       " 'snowball': 938,\n",
       " 'image': 939,\n",
       " 'handle': 940,\n",
       " 'pirate': 941,\n",
       " 'hide': 942,\n",
       " 'trot': 943,\n",
       " 'neon': 944,\n",
       " 'cake': 945,\n",
       " 'corn': 946,\n",
       " 'towel': 947,\n",
       " 'action': 948,\n",
       " 'racquet': 949,\n",
       " 'athlete': 950,\n",
       " 'tag': 951,\n",
       " 'curb': 952,\n",
       " 'attack': 953,\n",
       " 'shower': 954,\n",
       " 'sandal': 955,\n",
       " 'fake': 956,\n",
       " 'town': 957,\n",
       " 'porch': 958,\n",
       " 'student': 959,\n",
       " 'valley': 960,\n",
       " 'muzzled': 961,\n",
       " 'pit': 962,\n",
       " 'golf': 963,\n",
       " 'disc': 964,\n",
       " 'boardwalk': 965,\n",
       " 'grocery': 966,\n",
       " 'warm': 967,\n",
       " 'dust': 968,\n",
       " 'pop': 969,\n",
       " 'rollerblader': 970,\n",
       " 'pine': 971,\n",
       " 'jet': 972,\n",
       " 'ahead': 973,\n",
       " 'pair': 974,\n",
       " 'time': 975,\n",
       " 'sumo': 976,\n",
       " 'sculpture': 977,\n",
       " 'brush': 978,\n",
       " 'gesture': 979,\n",
       " 'print': 980,\n",
       " 'sell': 981,\n",
       " 'sheet': 982,\n",
       " 'themselves': 983,\n",
       " 'bow': 984,\n",
       " 'peek': 985,\n",
       " 'protest': 986,\n",
       " 'crosswalk': 987,\n",
       " 'cry': 988,\n",
       " 'scuba': 989,\n",
       " 'examine': 990,\n",
       " 'almost': 991,\n",
       " 'ship': 992,\n",
       " 'lip': 993,\n",
       " 'part': 994,\n",
       " 'woodland': 995,\n",
       " 'boulder': 996,\n",
       " 'class': 997,\n",
       " 'first': 998,\n",
       " 'strap': 999,\n",
       " 'beam': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this function will help us to understand what are the maximum length of words in all descriptions\n",
    "\n",
    "def max_length(descriptions):\n",
    "    return max(len(d.split()) for d in all_desc)\n",
    "\n",
    "max_length = max_length(descriptions)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function used to create inputs and output for tarining he model.\n",
    "## inputs (X1 - freatures of photo, X2 - input words index numbers from tokenizer ) & output ( y - output word )\n",
    "\n",
    "## ex: photo_name - desc [ dog walking on beach]\n",
    "## inputs: X1=features[photo_name] , X2=[ word_indexes of [dog] ] & output: y=[ word_index[walking] ]\n",
    "## inputs: X1=features[photo_name] , X2=[ word_indexes of [dog & walking] ] & output: y=[ word_index[on] ]\n",
    "## inputs: X1=features[photo_name] , X2=[ word_indexes of [dog & walking & on] ] & output: y=[ word_index[beach] ]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def create_seq(tokenizer,max_length,features,vocab_size,descriptions):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "            for i in range(1, len(seq)):\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                X1.append(features[key][0])\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "    return np.array(X1),np.array(X2),np.array(y)\n",
    "\n",
    "\n",
    "X1train, X2train, ytrain = create_seq(tokenizer,max_length,Train_features,vocab_size,Train_descriptions)\n",
    "X1test, X2test, ytest = create_seq(tokenizer,max_length,Dev_features,vocab_size,Dev_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 32, 256)      1711872     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 256)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          1048832     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6687)         1718559     dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,070,367\n",
      "Trainable params: 5,070,367\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "inputs1 = Input(shape=(4096,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "# sequence model\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "# decoder model\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "# tie it together [image, seq] [word]\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240851 samples, validate on 40680 samples\n",
      "Epoch 1/2\n",
      "240851/240851 [==============================] - 1763s 7ms/step - loss: 4.6437 - val_loss: 4.3242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.32419, saving model to model-ep001-loss4.644-val_loss4.324.h5\n",
      "Epoch 2/2\n",
      "240851/240851 [==============================] - 1732s 7ms/step - loss: 3.9900 - val_loss: 4.1462\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.32419 to 4.14624, saving model to model-ep002-loss3.990-val_loss4.146.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12f2296ee48>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# fit model\n",
    "model.fit([X1train, X2train], ytrain, epochs=2, verbose=1, callbacks=[checkpoint], validation_data=([X1test, X2test], ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model-ep002-loss3.990-val_loss4.146.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096,)\n",
      "(32,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_2 to have shape (4096,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-330-2b7d08b641b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_2 to have shape (4096,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# X1,X2 are inputs used in training of the model only\n",
    "\n",
    "## Here is the error i am getting if give single input feature and single seq\n",
    "\n",
    "t1 = X1[0]\n",
    "t2 = X2[0]\n",
    "\n",
    "print(t1.shape)\n",
    "print(t2.shape)\n",
    "\n",
    "model.predict([t1,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4096)\n",
      "(5, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.8348632e-11, 7.3000274e-06, 1.4644441e-04, ..., 5.4512877e-11,\n",
       "        4.0112712e-11, 6.6072490e-12],\n",
       "       [9.2933228e-10, 2.3872139e-02, 2.6460943e-01, ..., 1.3597146e-09,\n",
       "        3.7291636e-09, 1.5694909e-09],\n",
       "       [4.2562100e-11, 2.7341448e-02, 2.6034545e-02, ..., 9.2738012e-11,\n",
       "        2.2583951e-12, 1.3537351e-11],\n",
       "       [2.3922363e-13, 1.5173565e-01, 8.2067643e-05, ..., 2.6396187e-13,\n",
       "        8.9695590e-16, 3.6722256e-14],\n",
       "       [1.1709565e-10, 9.2951432e-03, 2.8177460e-03, ..., 1.8542291e-10,\n",
       "        1.5721802e-12, 1.6891324e-10]], dtype=float32)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here is the thing if i give list of input features and sequences, i am getting predictions\n",
    "\n",
    "t1 = X1[0:5]\n",
    "t2 = X2[0:5]\n",
    "\n",
    "print(np.array(t1).shape)\n",
    "print(np.array(t2).shape)\n",
    "\n",
    "model.predict([t1,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startseq dog be run through the snow with its mouth open in the snow with his mouth open in the snow in the snow with the top of the background in the snow\n"
     ]
    }
   ],
   "source": [
    "## So i am getting predictins, if i provide list of input features.\n",
    "## i have decided to make dummy of same feature and same input sequence\n",
    "\n",
    "## Here [ Photo ] is input features of photo & [ seqa ] dummy sequence( startseq )\n",
    "## Here i processed last prediction only from list of predictions added into input sequnce predicted till maximum length of words occured in training\n",
    "\n",
    "\n",
    "photo = list()\n",
    "seqa = list()\n",
    "in_seq = 'startseq'\n",
    "sequence = tokenizer.texts_to_sequences([in_seq])[0]\n",
    "sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "seqa.append(sequence[0])\n",
    "seqa.append(sequence[0])\n",
    "photo.append(test_features['3385593926_d3e9c21170'][0])\n",
    "photo.append(test_features['3385593926_d3e9c21170'][0])\n",
    "\n",
    "for i in range(max_length):\n",
    "    yhat = model.predict([photo,seqa], verbose=0)\n",
    "    a1 = np.argmax(yhat[len(yhat)-1])\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if(index == a1):\n",
    "            in_seq += ' ' + word\n",
    "    sequence = tokenizer.texts_to_sequences([in_seq])[0]\n",
    "    sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "    seqa.append(sequence[0])\n",
    "    photo.append(test_features['3385593926_d3e9c21170'][0])\n",
    "print(in_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "be\n",
      "run\n",
      "through\n",
      "the\n",
      "snow\n",
      "with\n",
      "its\n",
      "mouth\n",
      "open\n",
      "in\n",
      "the\n",
      "snow\n",
      "with\n",
      "his\n",
      "mouth\n",
      "open\n",
      "in\n",
      "the\n",
      "snow\n",
      "in\n",
      "the\n",
      "snow\n",
      "with\n",
      "the\n",
      "top\n",
      "of\n",
      "the\n",
      "background\n",
      "in\n",
      "the\n",
      "snow\n"
     ]
    }
   ],
   "source": [
    "## Here is last predicted word in every iterations\n",
    "\n",
    "photo = list()\n",
    "seqa = list()\n",
    "in_seq = 'startseq'\n",
    "sequence = tokenizer.texts_to_sequences([in_seq])[0]\n",
    "sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "seqa.append(sequence[0])\n",
    "seqa.append(sequence[0])\n",
    "photo.append(test_features['3385593926_d3e9c21170'][0])\n",
    "photo.append(test_features['3385593926_d3e9c21170'][0])\n",
    "\n",
    "for i in range(max_length):\n",
    "    yhat = model.predict([photo,seqa], verbose=0)\n",
    "    a1 = np.argmax(yhat[len(yhat)-1])\n",
    "    word = word_for_id(a1, tokenizer)\n",
    "    print(word)\n",
    "    in_seq += ' ' + word\n",
    "    sequence = tokenizer.texts_to_sequences([in_seq])[0]\n",
    "    sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "    seqa.append(sequence[0])\n",
    "    photo.append(test_features['3385593926_d3e9c21170'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error : I am predicting 32 words, ie: maximum no.of words for a description used in training\n",
    "\n",
    "## Questions:\n",
    "\n",
    "## for some of images i dont need to generate 32 words, caption can come in 10-15 words\n",
    "## If i get 'none' as a predicted word, so there i can stop iteration and i can show the description\n",
    "\n",
    "## If i need to get 'none' as predicted word what should i do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
